{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "963f50d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For local testing\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress TensorFlow warnings\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pathlib\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "# Metrics、Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c622ac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = pathlib.Path('./dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0129736e",
   "metadata": {},
   "source": [
    "### 分割 train、validation、test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cedd56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n",
      "Using 22968 files for training.\n",
      "Found 28709 files belonging to 7 classes.\n",
      "Using 5741 files for validation.\n",
      "Found 7178 files belonging to 7 classes.\n",
      "Class names: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "# 載入訓練和驗證資料集（從 train 資料夾中分割 20% 作為驗證集）\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"train\",\n",
    "    color_mode='grayscale',\n",
    "    image_size=(224, 224),  # 調整為 224x224 以適配 VGG16\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    label_mode='categorical',\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"train\",\n",
    "    color_mode='grayscale',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    label_mode='categorical',\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"test\",\n",
    "    color_mode='grayscale',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "class_names = train_dataset.class_names\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "# 定義函數將灰階圖像轉換為 RGB（複製單通道到三通道）\n",
    "def grayscale_to_rgb(image, label):\n",
    "    image = tf.image.grayscale_to_rgb(image)  # 將灰階圖像轉為 RGB\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc4250d",
   "metadata": {},
   "source": [
    "## 正規化、加入緩存載入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4003beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 應用轉換\n",
    "train_dataset = train_dataset.map(grayscale_to_rgb)\n",
    "val_dataset = val_dataset.map(grayscale_to_rgb)\n",
    "test_dataset = test_dataset.map(grayscale_to_rgb)\n",
    "\n",
    "# 正規化圖像像素值到 [0, 1]\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "\n",
    "# 資料增強\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomTranslation(0.1, 0.1)\n",
    "])\n",
    "train_dataset_augmentation = train_dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "\n",
    "# 優化資料載入\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "train_dataset_augmentation = train_dataset_augmentation.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab9dc22",
   "metadata": {},
   "source": [
    "### Model 1 CNN basic 4 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50932c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg16 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m14,714,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │         \u001b[38;5;34m1,799\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,847,815</span> (56.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,847,815\u001b[0m (56.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,127</span> (520.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m133,127\u001b[0m (520.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# 載入 VGG16 模型（不包括頂層全連接層，並使用預訓練權重）\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# 凍結 VGG16 的預訓練層\n",
    "base_model.trainable = False\n",
    "\n",
    "# 構建模型\n",
    "inputs = layers.Input(shape=(224, 224, 3))\n",
    "x = base_model(inputs, training=False)  # 使用 VGG16 提取特徵\n",
    "x = layers.GlobalAveragePooling2D()(x)  # 全局平均池化，減少參數量\n",
    "x = layers.Dense(256, activation='relu')(x)  # 全連接層\n",
    "x = layers.Dropout(0.5)(x)  # 防止過擬合\n",
    "outputs = layers.Dense(len(class_names), activation='softmax')(x)  # 7 個類別\n",
    "\n",
    "# 創建模型\n",
    "model_vgg16 = models.Model(inputs, outputs)\n",
    "\n",
    "# 編譯模型（使用較小的學習率以適應遷移學習）\n",
    "model_vgg16.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),  # 較小的學習率\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 顯示模型結構\n",
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f99df5",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48814472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m147/718\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:19\u001b[0m 455ms/step - accuracy: 0.2091 - loss: 2.0148"
     ]
    }
   ],
   "source": [
    "# 設置回調\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"./models/best_vgg16_model.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\"\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# 訓練模型\n",
    "history_vgg16 = model_vgg16.fit(\n",
    "    train_dataset_augmentation,\n",
    "    epochs=50,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977a5b3",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, model):\n",
    "    # 最終評估：在測試集上計算準確率和損失\n",
    "    test_loss, test_acc = model.evaluate(test_dataset)\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"Test Accuracy: {test_acc}\")\n",
    "\n",
    "    # 混淆矩陣與分類報告（使用 test_dataset）\n",
    "    # 獲取真實標籤\n",
    "    y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "    y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "    # 預測標籤\n",
    "    y_pred = model.predict(test_dataset)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    # 檢查形狀是否一致\n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError(f\"Mismatch between y_true ({len(y_true)}) and y_pred ({len(y_pred)}) lengths!\")\n",
    "\n",
    "    # 打印混淆矩陣\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"Confusion Matrix (Test Set):\\n\", cm)\n",
    "\n",
    "    # 繪製混淆矩陣熱圖\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix (Test Set)')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "    # 打印分類報告\n",
    "    print(\"Classification Report (Test Set):\\n\", classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "    # 繪製訓練曲線（不變）\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    # 損失曲線\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss', color='blue')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # 準確率曲線\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # 調整佈局並顯示\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 繪製訓練歷史\n",
    "plot_training_history(history_vgg16, model_vgg16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
